{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning"
      ],
      "metadata": {
        "id": "KoB9HxS41WVl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Package"
      ],
      "metadata": {
        "id": "WIkCxsrq0XCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip install scikit-learn pandas numpy"
      ],
      "metadata": {
        "id": "emkiDk1s6qSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Dataset"
      ],
      "metadata": {
        "id": "lom2aY7bmovO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer"
      ],
      "metadata": {
        "id": "a2dKyBMxpC0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 加載數據集\n",
        "data = load_breast_cancer()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target"
      ],
      "metadata": {
        "id": "IzqEm68_kPM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 顯示資料夾詳細訊息\n",
        "df.info()"
      ],
      "metadata": {
        "id": "zUNO0ckzleB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "onpFvgBvkaX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail(5)"
      ],
      "metadata": {
        "id": "45kogT7aqTsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "if7hu-88zrPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check Target Distributed"
      ],
      "metadata": {
        "id": "i9Kzd4Y7nrS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 檢查 target 欄位的分佈\n",
        "# To Do\n",
        "\n",
        "target_distribution =\n",
        "print(target_distribution)"
      ],
      "metadata": {
        "id": "LOVjUBxInra7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "Cj4EubUjmwvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 檢查每個欄位是否存在缺失值\n",
        "# To Do\n",
        "\n",
        "missing_values =\n",
        "print(missing_values)"
      ],
      "metadata": {
        "id": "igb_iarIm1Ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Missing Values"
      ],
      "metadata": {
        "id": "kxY-fU-IlTN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 設置隨機種子以便結果可重現\n",
        "np.random.seed(0)\n",
        "\n",
        "# 計算需要設置為缺失值的總數量\n",
        "nan_fraction = 0.1  # 10% 的數據設置為 NaN\n",
        "num_nans = int(np.floor(nan_fraction * df.size))\n",
        "\n",
        "# 確保 target 欄位不會被選中\n",
        "columns_to_select = df.columns[:-1]  # 排除 'target' 欄位\n",
        "\n",
        "# 隨機選擇行和列\n",
        "for _ in range(num_nans):\n",
        "    row = np.random.choice(df.index)\n",
        "    col = np.random.choice(columns_to_select)\n",
        "    df.at[row, col] = np.nan\n",
        "\n",
        "# 檢查每個欄位的缺失值\n",
        "missing_values = df.isnull().sum()\n",
        "print(missing_values)"
      ],
      "metadata": {
        "id": "kBFVQvgTm1Ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "r1W88oVepe08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing the Missing Values"
      ],
      "metadata": {
        "id": "COaepYw9lcaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer"
      ],
      "metadata": {
        "id": "aLPiRwaBsPja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 簡單插補法 `SimpleImputer`"
      ],
      "metadata": {
        "id": "lKIeDf1umgoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 用均值填充部分欄位\n",
        "mean_fill_columns = ['mean radius', 'mean texture', 'mean perimeter']\n",
        "imputer_mean = SimpleImputer(strategy='mean')\n",
        "df[mean_fill_columns] = imputer_mean.fit_transform(df[mean_fill_columns])"
      ],
      "metadata": {
        "id": "vyDvx4Fit6UK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 用中位數填充部分欄位\n",
        "# To Do\n",
        "median_fill_columns = ['mean area', 'mean smoothness']\n",
        "imputer_median =\n",
        "df[median_fill_columns] = imputer_median.fit_transform(df[median_fill_columns])"
      ],
      "metadata": {
        "id": "zeZLvMcouIvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 用眾數填充部分欄位\n",
        "# To Do\n",
        "mode_fill_columns = ['mean compactness', 'mean concavity']\n",
        "imputer_mode =\n",
        "df[mode_fill_columns] = imputer_mode.fit_transform(df[mode_fill_columns])"
      ],
      "metadata": {
        "id": "AHPAfFIDuI2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 線性插補法 `interpolate`\n",
        "- 一種用於填充缺失值的方法\n",
        "- 使用已知資料點之間的直線來估計缺失值\n",
        "- 適用於時間序列數據或具有連續性特徵的數據\n",
        "\n",
        "``` python\n",
        "Before\n",
        "   mean concave points  mean symmetry\n",
        "0                  0.1            0.2\n",
        "1                  NaN            0.3\n",
        "2                  0.2            NaN\n",
        "3                  NaN            0.5\n",
        "4                  0.4            0.6\n",
        "\n",
        "After\n",
        "   mean concave points  mean symmetry\n",
        "0                  0.1            0.2\n",
        "1                  0.15           0.3\n",
        "2                  0.2            0.4\n",
        "3                  0.3            0.5\n",
        "4                  0.4            0.6\n",
        "\n",
        "```\n",
        "\n",
        "線性插補會在Index 0 和Index 2 的已知資料之間畫一條直線。這條直線的公式是 y = mx + b，其中 m 是斜率，b 是截距。斜率 m 是 (0.2 - 0.1) / (2 - 0) = 0.1 / 2 = 0.05"
      ],
      "metadata": {
        "id": "XkFT4aJrm-Rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 用線性插值填充部分欄位\n",
        "interpolate_fill_columns = ['mean concave points', 'mean symmetry']\n",
        "df[interpolate_fill_columns] = df[interpolate_fill_columns].interpolate()"
      ],
      "metadata": {
        "id": "mNY2GD7UuI8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN插補法 `KNNImputer`\n",
        "- 使用最近鄰居算法（K-Nearest Neighbors, KNN）來填補缺失值的一種方法\n",
        "- 基本思想是用資料集中與缺失值最近的K個數據點的值來估計該缺失值\n",
        "- 適用於資料間具有局部相似性或聚類特性的情況\n",
        "- `KNNImputer` 中的 `n_neighbors` 表示指定用於填補缺失值的最近鄰居數量，不包含本身的缺失值\n",
        "- 在填補缺失值中，`KNNImputer` 會找到資料集中與缺失值最近的 `n_neighbors` 個有效資料點，然後使用這些鄰居的值（通常是均值）來填補缺失值\n",
        "\n",
        "\n",
        "``` python\n",
        "Before\n",
        "   mean fractal dimension  radius error\n",
        "0                     0.10           1.1\n",
        "1                     0.15           NaN\n",
        "2                      NaN           1.3\n",
        "3                     0.20           1.4\n",
        "4                     0.25           NaN\n",
        "\n",
        "After\n",
        "   mean fractal dimension  radius error\n",
        "0                    0.10      1.100000\n",
        "1                    0.15      1.266667\n",
        "2                    0.175     1.300000\n",
        "3                    0.20      1.400000\n",
        "4                    0.25      1.266667\n",
        "```\n",
        "使用 KNN 算法計算出的鄰居值如下：\n",
        "\n",
        "對於 mean fractal dimension 欄位的索引 2 的缺失值：\n",
        "\n",
        "最近的鄰居是索引 0, 1, 3, 4，平均值是 (0.1 + 0.15 + 0.2 + 0.25) / 4 = 0.175\n",
        "\n",
        "對於 radius error 欄位的索引 1 的缺失值：\n",
        "\n",
        "最近的鄰居是索引 0, 2, 3，平均值是 (1.1 + 1.3 + 1.4) / 3 = 1.2667\n",
        "\n",
        "對於 radius error 欄位的索引 4 的缺失值：\n",
        "\n",
        "最近的鄰居是索引 0, 1, 2, 3，平均值是 (1.1 + 1.2667 + 1.3 + 1.4) / 4 = 1.2667\n"
      ],
      "metadata": {
        "id": "pUPG_6uwrF6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. 用KNN填充部分欄位\n",
        "knn_fill_columns = ['mean fractal dimension', 'radius error']\n",
        "knn_imputer = KNNImputer(n_neighbors=5)\n",
        "df[knn_fill_columns] = knn_imputer.fit_transform(df[knn_fill_columns])"
      ],
      "metadata": {
        "id": "JhLac5pQuJCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 插補特定數值"
      ],
      "metadata": {
        "id": "c1NoGe7auwEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. 用特定值填充部分欄位\n",
        "specific_value_fill_columns = ['texture error', 'perimeter error']\n",
        "df[specific_value_fill_columns] = df[specific_value_fill_columns].fillna(0)"
      ],
      "metadata": {
        "id": "-_39zoTnuf-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Re-check Missing Values"
      ],
      "metadata": {
        "id": "sOskhCCUu02z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 檢查處理後每個欄位的缺失值\n",
        "missing_values_after = df.isnull().sum()\n",
        "print(missing_values_after)"
      ],
      "metadata": {
        "id": "1ZkwL6OXukCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 多重插補法 `IterativeImputer`\n",
        "- 用於填補資料集中的缺失值\n",
        "- 迭代地使用其他特徵來估計缺失值\n",
        "- 優點在於可充分利用數據集中所有可用的信息來進行插補，通常比簡單的插補方法（如均值插補或中位數插補）更加精確\n",
        "\n",
        "\n",
        "常用參數\n",
        "\n",
        "`max_iter`默認值：10\n",
        "\n",
        "說明：最大迭代次數。插補過程將重複這麼多次，直到結果收斂或達到最大迭代次數。\n",
        "\n",
        "`n_nearest_features`默認值：None\n",
        "\n",
        "說明：用於插補的最近鄰居特徵的數量。如果設置為 None，則使用所有特徵。\n",
        "\n",
        "`initial_strategy`默認值：'mean'\n",
        "\n",
        "說明：初始插補策略，用於第一次填補缺失值。選項有 'mean'、'median'、'most_frequent'。\n",
        "\n",
        "`imputation_order`默認值：'ascending'\n",
        "\n",
        "說明：插補順序。選項有 'ascending'（從缺失值最少的特徵開始）、'descending'（從缺失值最多的特徵開始）、'roman'（按列順序）、'arabic'（按列逆序）和 'random'（隨機順序）。\n",
        "\n",
        "`random_state`默認值：None\n",
        "\n",
        "說明：控制隨機數生成器的種子，以保證結果的可重現性。"
      ],
      "metadata": {
        "id": "MYqyHj4FvqyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 剩餘欄位的缺失值處理\n",
        "remaining_columns = ['area error', 'smoothness error', 'compactness error',\n",
        "                     'concavity error', 'concave points error', 'symmetry error',\n",
        "                     'fractal dimension error', 'worst radius', 'worst texture',\n",
        "                     'worst perimeter', 'worst area', 'worst smoothness',\n",
        "                     'worst compactness', 'worst concavity', 'worst concave points',\n",
        "                     'worst symmetry', 'worst fractal dimension']\n",
        "\n",
        "# 7. 使用IterativeImputer填充\n",
        "iterative_imputer = IterativeImputer(random_state=0,\n",
        "                                     max_iter=50,\n",
        "                                     n_nearest_features=None,\n",
        "                                     imputation_order='ascending',\n",
        "                                     initial_strategy='median',\n",
        ")\n",
        "\n",
        "df[remaining_columns] = iterative_imputer.fit_transform(df[remaining_columns])"
      ],
      "metadata": {
        "id": "NjxXEGx_vQSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 檢查處理後每個欄位的缺失值\n",
        "missing_values_final = df.isnull().sum()\n",
        "print(missing_values_final)"
      ],
      "metadata": {
        "id": "J33ivhgEv1FQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Normalization"
      ],
      "metadata": {
        "id": "OkmkMVnizcE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, MaxAbsScaler"
      ],
      "metadata": {
        "id": "Wj7_BTKX1ub7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "nxxEEMYDzkId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Min-Max Scaling（最小-最大縮放）\n",
        "- 將資料縮放到 [0, 1] 的範圍內。"
      ],
      "metadata": {
        "id": "Qn0oZ3xL17Op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Min-Max Scaling（最小-最大縮放）\n",
        "scaler = MinMaxScaler()\n",
        "normalized_df_min_max = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
        "normalized_df_min_max"
      ],
      "metadata": {
        "id": "QHGW-NMH1y0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 假設 'target' 是目標欄位的名稱\n",
        "target_column = 'target'\n",
        "\n",
        "# 分離特徵和目標欄位\n",
        "features = df.drop(columns=[target_column])\n",
        "target = df[target_column]\n",
        "\n",
        "# 進行 Min-Max Scaling 只對特徵欄位\n",
        "scaler = MinMaxScaler()\n",
        "normalized_min_max_features = pd.DataFrame(scaler.fit_transform(features), columns=features.columns)\n",
        "\n",
        "# 將目標欄位添加回去\n",
        "normalized_df_min_max = pd.concat([normalized_min_max_features, target.reset_index(drop=True)], axis=1)\n",
        "normalized_df_min_max"
      ],
      "metadata": {
        "id": "16S__pjeI2vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Z-Score Standardization（標準化）\n",
        "- 將資料縮放為均值為0，標準差為1。"
      ],
      "metadata": {
        "id": "mNveomHM16Od"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Z-Score Standardization（標準化）\n",
        "scaler = StandardScaler()\n",
        "normalized_df_z_score = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
        "normalized_df_z_score"
      ],
      "metadata": {
        "id": "OHg22VZo16UY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_z_score_features = pd.DataFrame(scaler.fit_transform(features), columns=features.columns)\n",
        "\n",
        "# 將目標欄位添加回去\n",
        "normalized_df_z_score = pd.concat([normalized_z_score_features, target.reset_index(drop=True)], axis=1)\n",
        "normalized_df_z_score"
      ],
      "metadata": {
        "id": "yo-aigvjKpcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Robust Scaler（穩健縮放器）\n",
        "- 基於中位數和四分位數範圍進行縮放，對於含有離群值的資料集更為穩健。"
      ],
      "metadata": {
        "id": "K5rj8PsY16gO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Robust Scaler（穩健縮放器）\n",
        "scaler = RobustScaler()\n",
        "\n",
        "# To Do\n"
      ],
      "metadata": {
        "id": "SuEl8fE916l7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Max Abs Scaler（最大絕對值縮放器）\n",
        "- 將資料縮放到 [-1, 1] 的範圍內，適合稀疏資料集。"
      ],
      "metadata": {
        "id": "VSzdGOnc2UVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Max Abs Scaler（最大絕對值縮放器）\n",
        "# To Do\n"
      ],
      "metadata": {
        "id": "57TmlE8G2Ucz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split Train & Test Dataset"
      ],
      "metadata": {
        "id": "eB_7bJ6rwBSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 加載數據集\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "9V4h45KYwGpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Traning & Evaluate Model Performance"
      ],
      "metadata": {
        "id": "4-9WP3k5m1my"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "ZYLeWL7A1nq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 朴素貝葉斯(Naive Bayes, NB)"
      ],
      "metadata": {
        "id": "szwGGjtN2njS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# 建立模型\n",
        "GNB_model = GaussianNB()\n",
        "GNB_model.fit(X_train, y_train)\n",
        "\n",
        "# 預測\n",
        "predictions = GNB_model.predict(X_test)"
      ],
      "metadata": {
        "id": "opK-ImXxm4oI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "YjPMfzLM1sVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
        "print(\"Precision:\", precision_score(y_test, predictions))\n",
        "print(\"Recall:\", recall_score(y_test, predictions))\n",
        "print(\"F1 Score:\", f1_score(y_test, predictions))"
      ],
      "metadata": {
        "id": "PTAIMeAC1se3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, predictions, digits=5))"
      ],
      "metadata": {
        "id": "zFIkVQ_42DSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 線性回歸（Linear Regression, LR）"
      ],
      "metadata": {
        "id": "4w-UhFia2uNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# 建立模型\n",
        "LR_model = LogisticRegression(max_iter=10000)\n",
        "LR_model.fit(X_train, y_train)\n",
        "\n",
        "# 預測\n",
        "predictions = LR_model.predict(X_test)\n",
        "print(classification_report(y_test, predictions, digits=5))"
      ],
      "metadata": {
        "id": "5lp2Ui3N2SIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 決策樹（Decision Tree, DT）"
      ],
      "metadata": {
        "id": "erBy3UQ23GmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# To Do"
      ],
      "metadata": {
        "id": "CmtETLBA27je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 隨機森林（Random Forest, RF）"
      ],
      "metadata": {
        "id": "BXrgz0cg3nkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# To Do"
      ],
      "metadata": {
        "id": "Wa2lObUn28Gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 支持向量機（Support Vector Machine, SVM）"
      ],
      "metadata": {
        "id": "DrGXb-0k33FZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "\n",
        "# 建立模型\n",
        "SVM_model = svm.SVC()\n",
        "SVM_model.fit(X_train, y_train)\n",
        "\n",
        "# 預測\n",
        "predictions = SVM_model.predict(X_test)\n",
        "print(classification_report(y_test, predictions, digits=5))"
      ],
      "metadata": {
        "id": "6h__YZYh28Pf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 多層感知機（Multilayer Perceptron, MLP）"
      ],
      "metadata": {
        "id": "eyRd_Jwq383u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# 建立模型\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(50, 30), max_iter=1000)\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# 預測\n",
        "predictions = mlp.predict(X_test)\n",
        "print(classification_report(y_test, predictions, digits=5))"
      ],
      "metadata": {
        "id": "ds2bKicC39Cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "0pYRK1xg4G17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# To Do"
      ],
      "metadata": {
        "id": "Krf4kwcC4G8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LightGBM"
      ],
      "metadata": {
        "id": "S0Ee_64i4PO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "# 建立模型\n",
        "LGBM_model = lgb.LGBMClassifier(verbose=-1)\n",
        "LGBM_model.fit(X_train, y_train)\n",
        "\n",
        "# 預測\n",
        "predictions = LGBM_model.predict(X_test)\n",
        "print(classification_report(y_test, predictions, digits=5))"
      ],
      "metadata": {
        "id": "CdDrG7Yc4PVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K Fold Cross Validation"
      ],
      "metadata": {
        "id": "qqUf7h72mn6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary of classifiers for baseline comparison\n",
        "classifiers = {\n",
        "    'CNB': GaussianNB(),\n",
        "    'LR': LogisticRegression(random_state=42, max_iter=10000),\n",
        "    'DT': DecisionTreeClassifier(random_state=42),\n",
        "    'RF': RandomForestClassifier(random_state=42),\n",
        "    'SVM': svm.SVC(probability=True, random_state=42),  # 設定 probability=True 以獲得概率\n",
        "    'MLP': MLPClassifier(random_state=42, max_iter=1000),  # 設定 max_iter 以防 MLPClassifier 收斂問題\n",
        "    'XGBoost': xgb.XGBClassifier(random_state=42),\n",
        "    'LightGBM': lgb.LGBMClassifier(random_state=42, verbose=-1),\n",
        "}"
      ],
      "metadata": {
        "id": "o7VK4ajdnAbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# 讀取數據集\n",
        "X = df.drop('target', axis=1)  # 刪除目標欄位，保留特徵\n",
        "y = df['target']  # 目標欄位\n",
        "\n",
        "# 定義 10 折交叉驗證\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# 遍歷分類器字典\n",
        "for name, classifier in classifiers.items():\n",
        "    y_trues = []  # 用來存儲真實標籤\n",
        "    y_preds = []  # 用來存儲預測標籤\n",
        "    y_probs = []  # 用來存儲預測概率\n",
        "\n",
        "    # 遍歷每一折交叉驗證\n",
        "    for train_index, val_index in tqdm(kf.split(X), desc=f'{name} 10-Fold CV'):\n",
        "        # 使用 iloc 來基於索引選取數據\n",
        "        X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
        "        y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "        # 訓練分類器\n",
        "        classifier.fit(X_train_fold, y_train_fold)\n",
        "        # 預測標籤\n",
        "        y_pred = classifier.predict(X_val_fold)\n",
        "        # 預測概率，儲存預測結果為1個概率\n",
        "        y_prob = classifier.predict_proba(X_val_fold)[:, 1]\n",
        "\n",
        "        # 將結果加入列表\n",
        "        y_trues.extend(y_val_fold)\n",
        "        y_preds.extend(y_pred)\n",
        "        y_probs.extend(y_prob)\n",
        "\n",
        "    # 輸出 10 折交叉驗證報告\n",
        "    print(f'{name} 10-Fold Cross Validation Report:\\n')\n",
        "    print(classification_report(y_trues, y_preds, digits=5))\n",
        "\n",
        "    # 將列表轉換為 NumPy 陣列\n",
        "    y_trues = np.array(y_trues)\n",
        "    y_preds = np.array(y_preds)\n",
        "    y_probs = np.array(y_probs)\n",
        "\n",
        "    # 創建 DataFrame 來存儲結果\n",
        "    df_results = pd.DataFrame({\n",
        "        \"model_name\": [name] * len(y_trues),\n",
        "        \"model_preds\": y_preds,\n",
        "        \"model_labels\": y_trues,\n",
        "        \"model_prob\": y_probs\n",
        "    })\n",
        "\n",
        "    # 保存結果到 pickle 文件\n",
        "    result_path = f\"{name}_10Folds.pkl\"\n",
        "    df_results.to_pickle(result_path)\n",
        "\n",
        "    # 保存模型到 pickle 文件\n",
        "    model_path = f\"{name}_model.pkl\"\n",
        "    with open(model_path, 'wb') as file:\n",
        "        pickle.dump(classifier, file)\n"
      ],
      "metadata": {
        "id": "PG5B1HEm7xKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot the Curve"
      ],
      "metadata": {
        "id": "K-Ja-seMLvLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AUROC (ROC curve)"
      ],
      "metadata": {
        "id": "-dLyHfx-3o8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# 定義模型名稱\n",
        "model_names = ['CNB', 'LR', 'DT', 'RF', 'SVM', 'MLP', 'XGBoost', 'LightGBM']\n",
        "\n",
        "# 設置繪圖區域大小\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "# 設置繪圖區域背景顏色及邊框顏色\n",
        "ax = plt.axes()\n",
        "ax.set_facecolor(\"white\")\n",
        "ax.spines[\"top\"].set_color(\"#3C3C3C\")\n",
        "ax.spines[\"bottom\"].set_color(\"#3C3C3C\")\n",
        "ax.spines[\"left\"].set_color(\"#3C3C3C\")\n",
        "ax.spines[\"right\"].set_color(\"#3C3C3C\")\n",
        "\n",
        "\n",
        "for name in model_names:\n",
        "\n",
        "    # 讀取保存的模型結果文件\n",
        "    df_results = pd.read_pickle(f\"{name}_10Folds.pkl\")\n",
        "\n",
        "    # 提取模型預測結果和真實標籤\n",
        "    y_true = df_results[\"model_labels\"]\n",
        "    y_prob = df_results[\"model_prob\"]\n",
        "\n",
        "    # 計算假陽性率和真陽性率\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # 繪製ROC曲線\n",
        "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.4f})')\n",
        "\n",
        "# 設置網格顏色\n",
        "plt.grid(True, color=\"#9D9D9D\")\n",
        "\n",
        "# 繪製對角線\n",
        "plt.plot([0, 1], [0, 1], color='#BEBEBE', linestyle='--')\n",
        "\n",
        "# 設置X軸刻度和標籤\n",
        "plt.xticks(np.arange(0.0, 1.05, step=0.2))\n",
        "plt.xlabel(\"1-Specificity\", fontsize=14)\n",
        "\n",
        "# 設置Y軸刻度和標籤\n",
        "plt.yticks(np.arange(0.0, 1.05, step=0.2))\n",
        "plt.ylabel(\"Sensitivity\", fontsize=14)\n",
        "\n",
        "# 設置圖表標題\n",
        "plt.title('Receiver Operating Characteristic Curve', fontweight='bold', fontsize=15)\n",
        "\n",
        "# 設置圖例\n",
        "plt.legend(prop={'size': 13}, loc='lower right', facecolor=\"white\")\n",
        "\n",
        "# 保存圖表為PNG圖片\n",
        "plt.savefig(f\"AUROC.png\", dpi=300)\n",
        "\n",
        "# 顯示圖表\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AZ3fxGPfLznY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AUPRC ( PR Curve)"
      ],
      "metadata": {
        "id": "nuLfrfwIPeXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "\n",
        "# 定義模型名稱\n",
        "model_names = ['CNB', 'LR', 'DT', 'RF', 'SVM', 'MLP', 'XGBoost', 'LightGBM']\n",
        "\n",
        "# 設置繪圖區域大小\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "# 設置繪圖區域背景顏色及邊框顏色\n",
        "ax = plt.axes()\n",
        "ax.set_facecolor(\"white\")\n",
        "ax.spines[\"top\"].set_color(\"#3C3C3C\")\n",
        "ax.spines[\"bottom\"].set_color(\"#3C3C3C\")\n",
        "ax.spines[\"left\"].set_color(\"#3C3C3C\")\n",
        "ax.spines[\"right\"].set_color(\"#3C3C3C\")\n",
        "\n",
        "for name in model_names:\n",
        "\n",
        "    # 讀取保存的模型結果文件\n",
        "    df_results = pd.read_pickle(f\"{name}_10Folds.pkl\")\n",
        "\n",
        "    # 提取模型預測結果和真實標籤\n",
        "    y_true = df_results[\"model_labels\"]\n",
        "    y_prob = df_results[\"model_prob\"]\n",
        "\n",
        "    # 計算精確率和召回率\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
        "    pr_auc = auc(recall, precision)\n",
        "\n",
        "    # 繪製PR曲線\n",
        "    plt.plot(recall, precision, lw=2, label=f'{name} (AP = {pr_auc:.4f})')\n",
        "\n",
        "# 設置網格顏色\n",
        "plt.grid(True, color=\"#9D9D9D\")\n",
        "\n",
        "# 繪製對角線\n",
        "plt.plot([0, 1], [0, 0], color='#BEBEBE', linestyle='--')\n",
        "\n",
        "# 設置X軸刻度和標籤\n",
        "plt.xticks(np.arange(0.0, 1.05, step=0.2))\n",
        "plt.xlabel(\"Recall\", fontsize=14)\n",
        "\n",
        "# 設置Y軸刻度和標籤\n",
        "plt.yticks(np.arange(0.0, 1.05, step=0.2))\n",
        "plt.ylabel(\"Precision\", fontsize=14)\n",
        "\n",
        "# 設置圖表標題\n",
        "plt.title('Precision-Recall Curve', fontweight='bold', fontsize=15)\n",
        "\n",
        "# 設置圖例\n",
        "plt.legend(prop={'size': 13}, loc='lower left', facecolor=\"white\")\n",
        "\n",
        "# 保存圖表為PNG圖片\n",
        "plt.savefig(f\"PR_curve.png\", dpi=300)\n",
        "\n",
        "# 顯示圖表\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8n83GmYb-3QT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SHAP\n",
        "- [SHAP Wbesite](https://shap.readthedocs.io/en/latest/#)\n",
        "- TreeExplainer (XGBoost/LightGBM/CatBoost/scikit-learn models)"
      ],
      "metadata": {
        "id": "LpPo83G0QbVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install shap"
      ],
      "metadata": {
        "id": "WQBpJaE061bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "shap.initjs()"
      ],
      "metadata": {
        "id": "yL2I9iqaSA3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "metadata": {
        "id": "K1gDmdUHAp-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 加載數據集\n",
        "data = load_breast_cancer()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n"
      ],
      "metadata": {
        "id": "T4qibWWK961P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = lgb.LGBMClassifier(verbose=-1, random_seed=12)\n",
        "model.fit(X, y)"
      ],
      "metadata": {
        "id": "e5SJe1r2OHG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.TreeExplainer(model)\n",
        "shap_values = explainer(X, y)"
      ],
      "metadata": {
        "id": "oRQC0GwgOJ_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.beeswarm(shap_values)"
      ],
      "metadata": {
        "id": "XFdmuLXzNal7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.beeswarm(shap_values.abs, color=\"shap_red\")"
      ],
      "metadata": {
        "id": "yn1QPKUsd53B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.waterfall(shap_values[0])"
      ],
      "metadata": {
        "id": "i2RSafGOSZ7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.bar(shap_values, max_display=30)"
      ],
      "metadata": {
        "id": "kFJ5fREfSgrh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}